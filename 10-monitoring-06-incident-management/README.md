# 10.06. Инцидент-менеджмент  

Постмортем, на основе реального сбоя системы Github в 2018 году.  
[Источник](https://github.blog/2018-10-30-oct21-post-incident-analysis/)  

### Краткое описание инцидента  
21.10.2018 года GitHub столкнулся с инцидентом, который привел к ухудшению обслуживания в течение 24 часов и 11 минут. 
Пострадали несколько внутренних систем, что привело к отображению информации, которая была устаревшей и неконсистентной. 
На протяжении большей части инцидента GitHub также не мог обслуживать события webhook или создавать и публиковать 
сайты GitHub Pages. В конечном счете, никакие пользовательские данные не были потеряны.  

### Предшествующие события  
21 октября в 22:52 UTC проходили рутинные работы по техническому обслуживанию для замены неисправного оптического 
оборудования 100G.  

### Причина инцидента  
Потеря связи между сетевым центром и основным центром обработки данных на Восточном побережье США на 43 секунды.  

### Воздействие  
Это короткое отключение вызвало цепочку событий, которые привели к 24-часовому и 11-минутному ухудшению обслуживания.  

### Обнаружение  
Инцидент был замечен инженерами из команды быстрого реагирования.

### Таймлайн  
**2018 21 октября 22:52 UTC**  
Во время отсутствия сети, оркестратор, который был активен в основном дата центре, 
начал процесс отбора лидера, согласно алгоритму Raft. Дата центр Западного побережья и узлы облака Восточного побережья
смогли создать кворум и начать перебирать кластеры, чтобы направлять записи в дата центр Западного побережья. 
Когда связь была восстановлена, трафик записи сразу же начал направляться на новые праймериз Западного побережья. 
Серверы баз данных Восточного побережья содержали короткий период записей, которые не были 
реплицированы на объект Западного побережья.  

**2018 21 октября 22:54 UTC**  
Внутренние системы мониторинга начали генерировать оповещения, указывающие на то, что 
системы испытывают многочисленные сбои.  

**2018 21 октября 23:02 UTC**  
Инженеры из команды быстрого реагирования определили, что топологии многочисленных кластеров 
баз данных находятся в неожидаемом состоянии. 

**2018 21 октября 23:07 UTC**  
Ответственная группа решила вручную заблокировать внутренние инструменты развертывания, 
чтобы предотвратить внесение каких-либо дополнительных изменений.  

**2018 21 октября 23:09 UTC**  
Ответственная группа перевела сайт в желтый статус. Это действие автоматически эскалировало 
ситуацию в активный инцидент и отправило оповещение координатору инцидента.  

**2018 21 октября 23:11 UTC**  
Координатор инцидента присоединился и через две минуты принял решение на красный статус.  

**2018 21 октября 23:13 UTC**  
Были размещены дополнительные инженеры из команды разработчиков баз данных GitHub. Они 
начали исследовать текущее состояние, чтобы определить, какие действия необходимо предпринять, чтобы вручную настроить 
базу данных Восточного побережья в качестве основной для каждого кластера и перестроить топологию репликации.  

**2018 21 октября 23:19 UTC**  
Частично ухудшили удобство использования сайта, приостановив доставку 
webhook и сборки GitHub Pages вместо того, чтобы ставить под угрозу данные, которые уже получили от пользователей. 
Другими словами, стратегия заключалась в том, чтобы приоритизировать целостность данных, а не удобство использования 
сайта и время восстановления.  

**2018 22 октября 00:05 UTC**  
Инженеры начали разработку плана устранения несоответствий данных и внедрения процедур 
аварийного переключения для MySQL. План состоял в том, чтобы восстановить из резервных копий, синхронизировать реплики 
на обоих сайтах, вернуться к стабильной топологии обслуживания, а затем возобновить обработку заданий в очереди. Обновили 
наш статус, чтобы сообщить пользователям.  

**2018 22 октября 00:41 UTC**  
Был начат процесс резервного копирования для всех затронутых кластеров MySQL, и инженеры 
следили за прогрессом. Одновременно несколько команд инженеров изучали способы ускорения времени передачи и восстановления 
без дальнейшего ухудшения удобства использования сайта и риска повреждения данных.  

**2018 22 октября 06:51 UTC**  
Несколько кластеров завершили восстановление из резервных копий в дата центре на 
Восточном побережье и начали реплицировать новые данные с Западного побережья.  

**2018 22 октября 07:46 UTC**  
GitHub опубликовал сообщение в блоге.  

**2018 22 октября 11:12 UTC**  
Все праймериз баз данных снова установлены на Восточном побережье. Но все еще существовали 
десятки реплик для чтения баз данных, которые отставали от основного на несколько часов.  

**2018 22 октября 13:15 UTC**  
Пиковоя нагрузка трафика на GitHub.com, задержки репликации увеличиваются.  

**2018 22 октября 16:24 UTC**  
Провели аварийное переключение на исходную топологию, устранив проблемы немедленной 
задержки/доступности.  

**2018 22 октября 16:45 UTC**  
Балансировка возросшей нагрузки. Было поставлено в очередь более пяти миллионов hook событий 
и 80 тысяч сборок Pages.  

**2018 22 октября 23:03 UTC**  
Все ожидающие сборки веб-хуков и Pages были обработаны, а целостность и надлежащая работа 
всех систем были подтверждены. Статус сайта был обновлен до зеленого цвета.  

### Последующие действия  

* Устранение несоответствий данных, анализ журналов и определение, какие записи могут быть автоматически согласованы, 
а какие потребуют работы с пользователями.
* Коммуникации. Стремиться предоставить более точную информацию в будущем.
* Технические инициативы:
  * настроить конфигурацию, чтобы предотвратить продвижение праймериз баз данных через региональные границы
  * новый механизм отчетности о состоянии
  * поддержка избыточности N+1 на уровне объекта, цель - терпеть полный сбой одного центра обработки данных без влияния на пользователя
  * Занять более активную позицию в проверке наших предположений
* Организационные инициативы. Начать системную практику проверки сценариев неудач, прежде чем у них появится шанс повлиять на вас.

